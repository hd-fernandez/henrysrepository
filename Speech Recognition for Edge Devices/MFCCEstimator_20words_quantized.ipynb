{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "CJtV3uB7G2LF"
   },
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.optim as optim\n",
    "from sklearn import preprocessing\n",
    "from sklearn.utils import class_weight\n",
    "import os\n",
    "import sys\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "#from models import CNNQuantized\n",
    "#from models import ConvNet_smaller1\n",
    "# from models import ConvNet_300k\n",
    "# from models import ConvNet_144k\n",
    "# from models import ConvNet_580k\n",
    "from models import ConvNet_200k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# audio 8000 x 16000 -> (librosa -> 8000x20x126) not quantized -> train a classifer -> validation : 94%\n",
    "#  y  80000 x 20 (num of label)\n",
    "\n",
    "\n",
    "# audio 8000 x 16000 -> (librosa -> 8000x20x126) quantize -> train a classifer -> validation : 70%\n",
    "#  y  80000 x 20 (num of label)\n",
    "\n",
    "# audio 8000 x 16000 -> model (predict quantized librosa) -> 8000x20x126 -> a classifer -> output: 70%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hypothesis: for accuracy we don't think it matters if we use full frame or single frame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "_RKpa3F-G2I3"
   },
   "outputs": [],
   "source": [
    "class MFCCDNN(nn.Module):\n",
    "\tdef __init__(self):\n",
    "\t\tsuper().__init__()\n",
    "\t\tself.ln1 = nn.Linear(256, 228)\n",
    "\t\tself.ln2 = nn.Linear(228, 200)\n",
    "\t\tself.ln3 = nn.Linear(200, 164)\n",
    "\t\tself.ln4 = nn.Linear(164, 20)\n",
    "# \t\tself.ln5 = nn.Linear(128, 20)\n",
    "# \t\tself.ln6 = nn.Linear(64, 32)\n",
    "# \t\tself.ln7 = nn.Linear(32, 20)\n",
    "\n",
    "\n",
    "\t\tself.ln11 = nn.Linear(256, 256)\n",
    "\t\tself.ln12 = nn.Linear(256, 20)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\t#forward propogation\n",
    "\tdef forward(self, x):\n",
    "\t\tx = F.relu(self.ln1(x))\n",
    "\t\tx = F.relu(self.ln2(x))\n",
    "\t\tx = F.relu(self.ln3(x))\n",
    "# \t\tx = F.relu(self.ln4(x))\n",
    "# \t\tx = F.relu(self.ln5(x)) \n",
    "# \t\tx = F.relu(self.ln6(x))\n",
    "\t\tx = self.ln4(x)\n",
    "\n",
    "\t\treturn x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qf5YYNCQG2Gp",
    "outputId": "4c71403b-7ab2-4efe-82c3-c2df803221f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param count DNN: 211592\n",
      "param count CNN: 201207\n",
      "total param count:  412799\n"
     ]
    }
   ],
   "source": [
    "\n",
    "directory = 'C:/Users/hdfer/OneDrive/Desktop/MFCC_Estimator/final_model_20_words/'\n",
    "net = MFCCDNN()\n",
    "#conv_net = CNNQuantized()\n",
    "conv_net = ConvNet_200k()\n",
    "\n",
    "from collections import OrderedDict\n",
    "new_state_dict = OrderedDict()\n",
    "state_dict = torch.load(r'C:\\Users\\hdfer\\OneDrive\\Desktop\\MFCC_Estimator\\cnn_classifier_trimming\\nn05_quantized_200k_params.pt', map_location=torch.device('cpu'))\n",
    "# for k, v in state_dict.items():\n",
    "#     name = k[7:] # remove `module.`\n",
    "#     new_state_dict[name] = v\n",
    "# load params\n",
    "conv_net.load_state_dict(state_dict)\n",
    "\n",
    "# conv_net.load_state_dict(torch.load(directory+'nn05_quantized.pt', map_location=torch.device('cpu')))\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print('param count DNN:', count_parameters(net))\n",
    "print('param count CNN:', count_parameters(conv_net))\n",
    "print('total param count: ', count_parameters(net) + count_parameters(conv_net))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AB5ldZ4cG2EH",
    "outputId": "9cbfb883-ce4e-4d70-9630-1cf8bb5eda4f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvNet_200k(\n",
       "  (conv1): Conv2d(1, 26, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (dropout_conv): Dropout(p=0.2, inplace=False)\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(26, 26, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv3): Conv2d(26, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv4): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv5): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv6): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv7): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (dropout_fc): Dropout(p=0.4, inplace=False)\n",
       "  (fc1): Linear(in_features=4960, out_features=21, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = 'cpu'\n",
    "if torch.cuda.device_count() > 1:\n",
    "  net = nn.DataParallel(net)\n",
    "net.to(device)\n",
    "conv_net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8181,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels20 = np.load(r'C:\\Users\\hdfer\\OneDrive\\Desktop\\MFCC_Estimator\\final_model_20_words\\test_label_sf20.npy')\n",
    "labels20.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['down', 'eight', 'five', 'four', 'go', 'left', 'nine', 'no', 'off',\n",
       "       'on', 'one', 'right', 'seven', 'six', 'stop', 'three', 'two', 'up',\n",
       "       'yes', 'zero'], dtype='<U10')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(labels20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "desZPgF9G2B6"
   },
   "outputs": [],
   "source": [
    "X_train = np.load(directory + 'train_audio_sf20.npy')\n",
    "#y_train = np.load(directory+'train_mfcc_sf2.npy')\n",
    "# y_train = np.load(r'C:\\Users\\hdfer\\OneDrive\\Desktop\\MFCC_Estimator\\quantized\\y_train_quant.npy')\n",
    "\n",
    "\n",
    "y_train = np.load(r'C:\\Users\\hdfer\\OneDrive\\Desktop\\MFCC_Estimator\\quantized\\X_train_quant.npy')\n",
    "train_label = np.load(r'C:\\Users\\hdfer\\OneDrive\\Desktop\\MFCC_Estimator\\quantized\\y_train_quant.npy')\n",
    "# indx = (train_label == 'one') | (train_label == 'two') | (train_label == 'three') | (train_label == 'four') | (train_label =='five')\n",
    "# y_train = y_train[indx,]\n",
    "\n",
    "# l1 = ['one']\n",
    "# l1 = l1 * 3140\n",
    "# l2 = ['two']\n",
    "# l2 = l2 * 3111\n",
    "# train_class = l1 + l2\n",
    "\n",
    "X_test = np.load(directory+'test_audio_sf20.npy')\n",
    "#y_test = np.load(directory+'test_mfcc_sf2.npy') # low resolution mfcc\n",
    "#test_label = np.load(directory+'test_label_sf2.npy')\n",
    "\n",
    "y_test = np.load(r'C:\\Users\\hdfer\\OneDrive\\Desktop\\MFCC_Estimator\\quantized\\X_test_quant.npy')\n",
    "test_label = np.load(r'C:\\Users\\hdfer\\OneDrive\\Desktop\\MFCC_Estimator\\quantized\\y_test_quant.npy')\n",
    "# indx = (test_label == 'one') | (test_label == 'two') | (test_label == 'three') | (test_label == 'four') | (test_label =='five')\n",
    "# y_test = y_test[indx,]\n",
    "# test_label = test_label[indx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8181, 16000)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(61927, 16000)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['down', 'eight', 'five', 'four', 'go', 'left', 'nine', 'no', 'off',\n",
       "       'on', 'one', 'right', 'seven', 'six', 'stop', 'three', 'two', 'up',\n",
       "       'yes', 'zero'], dtype='<U10')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(test_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this notebook is taking unquantized audio and learning the quantized mfccs and still works at 95%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "is it possible we shuffled X_train and y_train and they're not aligned?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check how train / test_mfcc_sf2 were generated and see if they were sliced properly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for example we do line 23 in the cell above, did we do that the same way in generating sf2 data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['down', 'eight', 'five', 'four', 'go', 'left', 'nine', 'no', 'off',\n",
       "       'on', 'one', 'right', 'seven', 'six', 'stop', 'three', 'two', 'up',\n",
       "       'yes', 'zero'], dtype='<U10')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LObK2cG-X3bD",
    "outputId": "8129bf61-5f9b-4e19-c580-06fe281df50c",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(61927, 16000)\n",
      "(61927, 20, 126)\n",
      "(8181, 16000)\n",
      "(8181, 20, 126)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1e9ec87a5b0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(y_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "jzjCJBA8G1_m"
   },
   "outputs": [],
   "source": [
    "def reshape(data, hop_length=128, clip_size=256):\n",
    "  dim0 = int(((data.shape[1] * 2) + clip_size) * (data.shape[0] / clip_size))\n",
    "  new = np.zeros((dim0, clip_size))\n",
    "  j_max = int((data.shape[1] / hop_length))\n",
    "  for i in range(data.shape[0]):\n",
    "      for j in range(j_max + 1):\n",
    "          indx = int(j+(i*(clip_size/2 - 2)))\n",
    "          if (j == (j_max)):\n",
    "              new[indx] = np.zeros((clip_size))\n",
    "          elif (j == (j_max-1)):\n",
    "              temp = np.zeros(clip_size)\n",
    "              temp[0:int(clip_size/2)] = data[i, (j*hop_length):((j*hop_length) + int((clip_size/2)))]\n",
    "              new[indx] = temp\n",
    "          else:\n",
    "              new[indx] = data[i, (j*hop_length):(j*hop_length+clip_size)]\n",
    "  return new\n",
    "\n",
    "def flatten_data(data):\n",
    "  # t = y_train[:2]\n",
    "  c = 0\n",
    "  flat_data = np.zeros((data.shape[0] * data.shape[2], data.shape[1]))\n",
    "  # print(y_n.shape)\n",
    "  for i in range(data.shape[0]):\n",
    "    for k in range(data.shape[2]):\n",
    "      # print(t[i, :, k].shape)\n",
    "      flat_data[c] = data[i, :, k]\n",
    "      c+=1\n",
    "  # print(data.shape)\n",
    "  # flat_data = np.reshape(data, (data.shape[0] * data.shape[2], data.shape[1]), order='F')\n",
    "  return flat_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wpnckW4BG19N",
    "outputId": "ccea5826-bddb-4974-8bc3-bc3db64a2709"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7802802, 256)\n",
      "(7802802, 20)\n",
      "(1030806, 256)\n",
      "(1030806, 20)\n"
     ]
    }
   ],
   "source": [
    "X_train = reshape(X_train)\n",
    "X_test = reshape(X_test)\n",
    "y_train = flatten_data(y_train)\n",
    "y_test = flatten_data(y_test)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Jii800ThG163",
    "outputId": "1f32917d-bde7-43e9-9fc7-e4c5aed224f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15980138496\n"
     ]
    }
   ],
   "source": [
    "X_train = torch.from_numpy(X_train)\n",
    "\n",
    "print(X_train.element_size() * X_train.nelement())\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.classes_ = np.load(directory+'encoder.npy')\n",
    "# y_train = le.fit_transform(y_train)\n",
    "y_train = torch.from_numpy(y_train)\n",
    "\n",
    "X_test = torch.from_numpy(X_test)\n",
    "test_label = le.transform(test_label)\n",
    "y_test = torch.from_numpy(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1Opn7lVIG14k",
    "outputId": "dce54f61-ddc7-4fe7-cb31-bbd0d03fbe44"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([7802802, 256])\n",
      "torch.Size([7802802, 20])\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=3e-4)\n",
    "\n",
    "#create dataloaders for all 3 datasets\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "train_set = TensorDataset(X_train, y_train)\n",
    "train_dataloader = DataLoader(train_set, batch_size = 126, num_workers = 2, shuffle=True)\n",
    "\n",
    "\n",
    "test_set = TensorDataset(X_test, y_test)\n",
    "test_dataloader = DataLoader(test_set, batch_size = 126, num_workers = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SKIP CELL BELOW: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JZfOkP-2G12R",
    "outputId": "4f42272a-19c3-4b26-c5ad-4b8c39d78d35",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[1,    32] loss: 22419.579\n",
      "[1,    64] loss: 22227.449\n",
      "[1,    96] loss: 21515.805\n",
      "[1,   128] loss: 19965.839\n",
      "[1,   160] loss: 14990.385\n",
      "[1,   192] loss: 8740.840\n",
      "[1,   224] loss: 4822.647\n",
      "[1,   256] loss: 3756.872\n",
      "[1,   288] loss: 3047.480\n",
      "[1,   320] loss: 2933.642\n",
      "[1,   352] loss: 2645.500\n",
      "[1,   384] loss: 2504.575\n",
      "[1,   416] loss: 2335.264\n",
      "[1,   448] loss: 2282.461\n",
      "[1,   480] loss: 2184.822\n",
      "[1,   512] loss: 2084.520\n",
      "[1,   544] loss: 2074.876\n",
      "[1,   576] loss: 2059.148\n",
      "[1,   608] loss: 2007.374\n",
      "[1,   640] loss: 2002.853\n",
      "[1,   672] loss: 1989.189\n",
      "[1,   704] loss: 1999.536\n",
      "[1,   736] loss: 1975.817\n",
      "[1,   768] loss: 1907.822\n",
      "[1,   800] loss: 1952.312\n",
      "[1,   832] loss: 1937.484\n",
      "[1,   864] loss: 1933.773\n",
      "[1,   896] loss: 1912.803\n",
      "[1,   928] loss: 1926.327\n",
      "[1,   960] loss: 1931.069\n",
      "[1,   992] loss: 1866.317\n",
      "[1,  1024] loss: 1868.279\n",
      "[1,  1056] loss: 1882.997\n",
      "[1,  1088] loss: 1872.973\n",
      "[1,  1120] loss: 1857.532\n",
      "[1,  1152] loss: 1833.520\n",
      "[1,  1184] loss: 1862.207\n",
      "[1,  1216] loss: 1834.773\n",
      "[1,  1248] loss: 1806.955\n",
      "[1,  1280] loss: 1828.070\n",
      "[1,  1312] loss: 1826.136\n",
      "[1,  1344] loss: 1800.948\n",
      "[1,  1376] loss: 1816.559\n",
      "[1,  1408] loss: 1742.699\n",
      "[1,  1440] loss: 1689.972\n",
      "[1,  1472] loss: 1699.023\n",
      "[1,  1504] loss: 1698.030\n",
      "[1,  1536] loss: 1642.040\n",
      "[1,  1568] loss: 1624.540\n",
      "[1,  1600] loss: 1613.618\n",
      "[1,  1632] loss: 1584.944\n",
      "[1,  1664] loss: 1551.349\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\caffe2\\serialize\\inline_container.cc:300] . unexpected pos 1280 vs 1182",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[0;32m    379\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0m_open_zipfile_writer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 380\u001b[1;33m                 \u001b[0m_save\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    381\u001b[0m                 \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36m_save\u001b[1;34m(obj, zip_file, pickle_module, pickle_protocol)\u001b[0m\n\u001b[0;32m    603\u001b[0m         \u001b[0mnum_bytes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstorage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 604\u001b[1;33m         \u001b[0mzip_file\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite_record\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstorage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_ptr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_bytes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    605\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_5836/4212734420.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[1;31m# print(f'Total count: {total}, correct: {correct}')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mfile_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'mfcc-dnn-fill_this_in.pt'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     60\u001b[0m     \u001b[1;31m#print update every 32 batches\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m32\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m31\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[0;32m    379\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0m_open_zipfile_writer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    380\u001b[0m                 \u001b[0m_save\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 381\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    382\u001b[0m         \u001b[0m_legacy_save\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    383\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 260\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite_end_of_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    261\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    262\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: [enforce fail at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\caffe2\\serialize\\inline_container.cc:300] . unexpected pos 1280 vs 1182"
     ]
    }
   ],
   "source": [
    "# count = 0\n",
    "# for epoch in range(30):\n",
    "#   print(epoch)\n",
    "#   running_loss = 0.0\n",
    "\n",
    "#   for i, data in enumerate(train_dataloader):\n",
    "#     #get input data and labels\n",
    "#     inputs, labels = data\n",
    "\n",
    "#     #labels need to be LongTensor type for some reason\n",
    "#     labels = labels.type(torch.FloatTensor)\n",
    "\n",
    "#     #inputs need to be floats\n",
    "#     inputs = inputs.float()\n",
    "\n",
    "#     #reshape inputs as (channels, batch size, 20, 126)\n",
    "#     #(20, 126) at end should be constant due to our preprocessing of the\n",
    "#     #MFCCs\n",
    "#     # inputs = torch.reshape(inputs, (1, inputs.shape[0], 16000))\n",
    "#     # inputs = torch.permute(inputs, (1, 0))\n",
    "\n",
    "#     #send data to gpus\n",
    "#     inputs = inputs.to(device)\n",
    "#     labels = labels.to(device)\n",
    "#     # print(inputs.size())\n",
    "#     # print(labels.size())\n",
    "#     #zero the gradients in optimizer\n",
    "#     optimizer.zero_grad()\n",
    "\n",
    "#     #create predictions, calculate loss, backward propogation, then\n",
    "#     #update weights of model\n",
    "#     outputs = net(inputs)\n",
    "#     if(torch.count_nonzero(outputs) == 0):\n",
    "#       count += 1\n",
    "#     # loss = matrix_similarity_loss(outputs, labels)\n",
    "#     loss = criterion(outputs, labels)\n",
    "#     loss.backward()\n",
    "#     optimizer.step()\n",
    "\n",
    "#     #add loss\n",
    "#     running_loss += float(loss.item())\n",
    "\n",
    "#     # total = 0\n",
    "#     # outputs = torch.reshape(outputs, (1, outputs.shape[0], outputs.shape[1], outputs.shape[2]))\n",
    "#     # final_outputs = conv_net(outputs)\n",
    "\n",
    "#     # #calculate class with highest probability\n",
    "#     # _, predicted = torch.max(final_outputs.data, 1)\n",
    "#     # y_pred = predicted\n",
    "#     # # y_pred.extend(predicted)\n",
    "\n",
    "#     # #update total and correct counts\n",
    "#     # total += labels.size(0)\n",
    "#     # correct += (predicted == labels).sum().item()\n",
    "\n",
    "#     # print(f'Accuracy of the network on the {total} validation images: {100 * correct // total} %')\n",
    "#     # print(f'Total count: {total}, correct: {correct}')\n",
    "#     file_name = 'mfcc-dnn-fill_this_in.pt'\n",
    "#     torch.save(net.state_dict(), os.path.join(directory, file_name))\n",
    "#     #print update every 32 batches\n",
    "#     if i % 32 == 31:\n",
    "#       print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 32:.3f}')\n",
    "#       running_loss = 0.0\n",
    "# print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "qhZ6wDgwbUKN"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = MFCCDNN()\n",
    "state_dict1 = torch.load('mfcc-dnn-4layers-google.pt', map_location=torch.device('cpu'))\n",
    "net.load_state_dict(state_dict1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z9KgOxwC2Uf4"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "ZRxjWex0Hhao",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "32\n",
      "64\n",
      "96\n",
      "128\n",
      "160\n",
      "192\n",
      "224\n",
      "256\n",
      "288\n",
      "320\n",
      "352\n",
      "384\n",
      "416\n",
      "448\n",
      "480\n",
      "512\n",
      "544\n",
      "576\n",
      "608\n",
      "640\n",
      "672\n",
      "704\n",
      "736\n",
      "768\n",
      "800\n",
      "832\n",
      "864\n",
      "896\n",
      "928\n",
      "960\n",
      "992\n",
      "1024\n",
      "1056\n",
      "1088\n",
      "1120\n",
      "1152\n",
      "1184\n",
      "1216\n",
      "1248\n",
      "1280\n",
      "1312\n",
      "1344\n",
      "1376\n",
      "1408\n",
      "1440\n",
      "1472\n",
      "1504\n",
      "1536\n",
      "1568\n",
      "1600\n",
      "1632\n",
      "1664\n",
      "1696\n",
      "1728\n",
      "1760\n",
      "1792\n",
      "1824\n",
      "1856\n",
      "1888\n",
      "1920\n",
      "1952\n",
      "1984\n",
      "2016\n",
      "2048\n",
      "2080\n",
      "2112\n",
      "2144\n",
      "2176\n",
      "2208\n",
      "2240\n",
      "2272\n",
      "2304\n",
      "2336\n",
      "2368\n",
      "2400\n",
      "2432\n",
      "2464\n",
      "2496\n",
      "2528\n",
      "2560\n",
      "2592\n",
      "2624\n",
      "2656\n",
      "2688\n",
      "2720\n",
      "2752\n",
      "2784\n",
      "2816\n",
      "2848\n",
      "2880\n",
      "2912\n",
      "2944\n",
      "2976\n",
      "3008\n",
      "3040\n",
      "3072\n",
      "3104\n",
      "3136\n",
      "3168\n",
      "3200\n",
      "3232\n",
      "3264\n",
      "3296\n",
      "3328\n",
      "3360\n",
      "3392\n",
      "3424\n",
      "3456\n",
      "3488\n",
      "3520\n",
      "3552\n",
      "3584\n",
      "3616\n",
      "3648\n",
      "3680\n",
      "3712\n",
      "3744\n",
      "3776\n",
      "3808\n",
      "3840\n",
      "3872\n",
      "3904\n",
      "3936\n",
      "3968\n",
      "4000\n",
      "4032\n",
      "4064\n",
      "4096\n",
      "4128\n",
      "4160\n",
      "4192\n",
      "4224\n",
      "4256\n",
      "4288\n",
      "4320\n",
      "4352\n",
      "4384\n",
      "4416\n",
      "4448\n",
      "4480\n",
      "4512\n",
      "4544\n",
      "4576\n",
      "4608\n",
      "4640\n",
      "4672\n",
      "4704\n",
      "4736\n",
      "4768\n",
      "4800\n",
      "4832\n",
      "4864\n",
      "4896\n",
      "4928\n",
      "4960\n",
      "4992\n",
      "5024\n",
      "5056\n",
      "5088\n",
      "5120\n",
      "5152\n",
      "5184\n",
      "5216\n",
      "5248\n",
      "5280\n",
      "5312\n",
      "5344\n",
      "5376\n",
      "5408\n",
      "5440\n",
      "5472\n",
      "5504\n",
      "5536\n",
      "5568\n",
      "5600\n",
      "5632\n",
      "5664\n",
      "5696\n",
      "5728\n",
      "5760\n",
      "5792\n",
      "5824\n",
      "5856\n",
      "5888\n",
      "5920\n",
      "5952\n",
      "5984\n",
      "6016\n",
      "6048\n",
      "6080\n",
      "6112\n",
      "6144\n",
      "6176\n",
      "6208\n",
      "6240\n",
      "6272\n",
      "6304\n",
      "6336\n",
      "6368\n",
      "6400\n",
      "6432\n",
      "6464\n",
      "6496\n",
      "6528\n",
      "6560\n",
      "6592\n",
      "6624\n",
      "6656\n",
      "6688\n",
      "6720\n",
      "6752\n",
      "6784\n",
      "6816\n",
      "6848\n",
      "6880\n",
      "6912\n",
      "6944\n",
      "6976\n",
      "7008\n",
      "7040\n",
      "7072\n",
      "7104\n",
      "7136\n",
      "7168\n",
      "7200\n",
      "7232\n",
      "7264\n",
      "7296\n",
      "7328\n",
      "7360\n",
      "7392\n",
      "7424\n",
      "7456\n",
      "7488\n",
      "7520\n",
      "7552\n",
      "7584\n",
      "7616\n",
      "7648\n",
      "7680\n",
      "7712\n",
      "7744\n",
      "7776\n",
      "7808\n",
      "7840\n",
      "7872\n",
      "7904\n",
      "7936\n",
      "7968\n",
      "8000\n",
      "8032\n",
      "8064\n",
      "8096\n",
      "8128\n",
      "8160\n"
     ]
    }
   ],
   "source": [
    "######Testing#######\n",
    "correct = 0\n",
    "total = 0 \n",
    "test_loss = 0.0\n",
    "y_pred = []\n",
    "#use no_grad as we are testing\n",
    "with torch.no_grad():\n",
    "\n",
    "  #loop through test data\n",
    "  for i, data in enumerate(test_dataloader):\n",
    "    #gets inputs and labels\n",
    "    inputs, labels = data \n",
    "\n",
    "    #convert labels to long tensors\n",
    "    labels = labels.type(torch.FloatTensor)\n",
    "\n",
    "    #convert inputs to float\n",
    "    inputs = inputs.float()\n",
    "\n",
    "    #reshape inputs as (channels, batch size, 16000)\n",
    "    # inputs = torch.reshape(inputs, (1, inputs.shape[0], 16000))\n",
    "    # inputs = torch.permute(inputs, (1, 0, 2, 3))\n",
    "\n",
    "    #send data to gpus\n",
    "    inputs = inputs.to(device)\n",
    "    labels = labels.to(device)\n",
    "\n",
    "    # print(inputs.shape)\n",
    "    # print(labels.shape)\n",
    "    #predict outputs\n",
    "    outputs = net(inputs)\n",
    "    #outputs = labels # <- uncomment this to see best best possible performance (theoretical)\n",
    "    # print(outputs.shape)\n",
    "    # print(outputs.shape)\n",
    "    outputs = torch.reshape(outputs, (1, 1, outputs.shape[0], outputs.shape[1]))\n",
    "    # voutputs = torch.reshape(voutputs, (voutputs.shape[0], 1, voutputs.shape[1], voutputs.shape[2]))\n",
    "    outputs = torch.permute(outputs, (0, 1, 3, 2))\n",
    "    # print(outputs.shape )\n",
    "    outputs_final = conv_net(outputs)\n",
    "    # print(outputs_final.shape)\n",
    "    #calculate class with highest probability\n",
    "    predicted = np.array(torch.max(outputs_final.data, 1).indices)\n",
    "    # _, predicted = torch.max(outputs.data, 1) \n",
    "    y_pred.extend(predicted)\n",
    "\n",
    "    #update total and correct counts\n",
    "    # total += labels.size(0)\n",
    "    # loss = criterion(outputs, labels)\n",
    "    # test_loss += loss.item()\n",
    "\n",
    "    # test_label = torch.from_numpy(test_label)\n",
    "    # test_label = test_label.to(device)\n",
    "    # correct += (predicted == test_label).sum().item()\n",
    "\n",
    "    if (i%32==0):\n",
    "      print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8985454100965652"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(np.array(y_pred) == test_label) / len(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 8,\n",
       " 17,\n",
       " 8,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 6,\n",
       " 9,\n",
       " 17,\n",
       " 17,\n",
       " 14,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 2,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 9,\n",
       " 8,\n",
       " 17,\n",
       " 17,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 9,\n",
       " 17,\n",
       " 9,\n",
       " 9,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 9,\n",
       " 12,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 9,\n",
       " 17,\n",
       " 17,\n",
       " 8,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 3,\n",
       " 3,\n",
       " 8,\n",
       " 8,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 8,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 2,\n",
       " 17,\n",
       " 8,\n",
       " 13,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 2,\n",
       " 6,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 0,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 0,\n",
       " 8,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 9,\n",
       " 17,\n",
       " 17,\n",
       " 0,\n",
       " 8,\n",
       " 4,\n",
       " 17,\n",
       " 17,\n",
       " 6,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 9,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 13,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 9,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 2,\n",
       " 8,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 9,\n",
       " 17,\n",
       " 9,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 18,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 12,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 13,\n",
       " 1,\n",
       " 1,\n",
       " 12,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 2,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 17,\n",
       " 8,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 9,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 7,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 8,\n",
       " 8,\n",
       " 17,\n",
       " 8,\n",
       " 8,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 8,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 6,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 9,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 14,\n",
       " 17,\n",
       " 17,\n",
       " 8,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 8,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 9,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 1,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 17,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 14,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 9,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 11,\n",
       " 0,\n",
       " 7,\n",
       " 7,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 9,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 6,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 9,\n",
       " 6,\n",
       " 0,\n",
       " 0,\n",
       " 7,\n",
       " 0,\n",
       " 6,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 5,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 9,\n",
       " 9,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 6,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 6,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 10,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 7,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 18,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 7,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 6,\n",
       " 0,\n",
       " 0,\n",
       " 7,\n",
       " 0,\n",
       " 0,\n",
       " 7,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 12,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 7,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 10,\n",
       " 0,\n",
       " 0,\n",
       " 16,\n",
       " 0,\n",
       " 0,\n",
       " 7,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 7,\n",
       " 7,\n",
       " 0,\n",
       " 0,\n",
       " 7,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 18,\n",
       " 6,\n",
       " 18,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 18,\n",
       " 18,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 11,\n",
       " 5,\n",
       " 5,\n",
       " 18,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 6,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 6,\n",
       " 5,\n",
       " 18,\n",
       " 10,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 18,\n",
       " 18,\n",
       " 5,\n",
       " 15,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 18,\n",
       " 5,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 5,\n",
       " 6,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 17,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " ...]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "provenance": []
  },
  "gpuClass": "premium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
